{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be08d33-dd1d-4071-99f0-9997b922d0ce",
   "metadata": {},
   "source": [
    "# MNIST \n",
    "### **Feedforward Fully Connected SNN**\n",
    "\n",
    "This tutorial goes over how to train a simple feedforward SNN and deploy on HiAER Spike using our \n",
    "conversion pipline.\n",
    "\n",
    "### **Define a Feedforward SNN**\n",
    "To build a simple feedforward spiking neural network with PyTorch, we can use snnTorch, SpikingJelly or other deep learning frameworks that are based on PyTorch. Currently, our conversion pipline supports snnTorch and SpikingJelly. In this tutorial, we will be using SpikingJelly.\n",
    "\n",
    "Install the PyPi distribution of SpikingJelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c1238a-bb88-4a0e-9250-2ab4656dfaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spikingjelly in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (0.0.0.0.14)\n",
      "Requirement already satisfied: torch in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from spikingjelly) (1.12.1)\n",
      "Requirement already satisfied: matplotlib in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from spikingjelly) (3.4.3)\n",
      "Requirement already satisfied: numpy in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from spikingjelly) (1.22.4)\n",
      "Requirement already satisfied: tqdm in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from spikingjelly) (4.63.0)\n",
      "Requirement already satisfied: torchvision in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from spikingjelly) (0.13.1)\n",
      "Requirement already satisfied: scipy in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from spikingjelly) (1.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from matplotlib->spikingjelly) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from matplotlib->spikingjelly) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from matplotlib->spikingjelly) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from matplotlib->spikingjelly) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from matplotlib->spikingjelly) (2.8.2)\n",
      "Requirement already satisfied: typing_extensions in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from torch->spikingjelly) (4.3.0)\n",
      "Requirement already satisfied: requests in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from torchvision->spikingjelly) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from requests->torchvision->spikingjelly) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from requests->torchvision->spikingjelly) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from requests->torchvision->spikingjelly) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/export/isn/keli/miniconda3/lib/python3.9/site-packages (from requests->torchvision->spikingjelly) (3.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spikingjelly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83016a2-f759-47a1-a229-4266d4830efd",
   "metadata": {},
   "source": [
    "Import necessary libraries from SpikingJelly and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187bc8fa-aff2-41c8-b11c-9e062fe183b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikingjelly.activation_based import neuron, functional, surrogate\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786bffa-4f0f-4525-9879-a65dbc2e6f29",
   "metadata": {},
   "source": [
    "### **Model Architecture**\n",
    "Using SpikingJelly, we can define a simple 2-layer feedforward SNN model with 1000 hidden neurons. The PyTorch layer will act as synapses between the spiking neuron layers. \n",
    "#### **Surrogate Function**\n",
    "SpikingJelly and snnTorch both use backpropagation through time to train the spiking neural networks. However, because of the non-differentiability of spikes, surrogate gradients are used in place of the Heaviside function in the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0ab95c-1fc5-4a9c-b007-aa03197bfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module): \n",
    "    def __init__(self, features = 1000): \n",
    "        super().__init__() \n",
    "        self.flat = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(28 * 28, features, bias=False) \n",
    "        self.lif1 = neuron.LIFNode(surrogate_function=surrogate.ATan()) \n",
    "        self.linear2 = nn.Linear(features, 10, bias=False) \n",
    "        self.lif2 = neuron.LIFNode(surrogate_function=surrogate.ATan()) \n",
    "    def forward(self, x): \n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x) \n",
    "        x = self.lif1(x) \n",
    "        x = self.linear2(x) \n",
    "        x = self.lif2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0c7a1b-4357-4a41-85ca-9ca56bdb86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate the Network\n",
    "net = model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49d6d4-5124-4375-aa5c-6b98ded83a6f",
   "metadata": {},
   "source": [
    "### **Setting up the MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd241796-eebd-4400-8dc0-8d1eb177a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Download MNIST data from torch \n",
    "mnist_train = datasets.MNIST('data/mnist', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]))\n",
    "mnist_test = datasets.MNIST('data/mnist', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=128, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1b524-014e-4a13-81e3-4d918ed28c12",
   "metadata": {},
   "source": [
    "### **Training the SNN**\n",
    "Since we are using a static image dataset, we will first encode the image into spikes using the rate encoding function from spikingjelly. With rate encoding, the input feature determines the firing frequency and the neuron that fries the most is selected as the predicted class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83e51ba-4964-49c7-8b92-969923d8febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikingjelly.activation_based import encoding\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836f14da-e64b-41be-b20f-852a2d697de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the encoder and the time steps\n",
    "encoder = encoding.PoissonEncoder()\n",
    "num_steps = 20\n",
    "\n",
    "#Define training parameters\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#Copy netowrk to device \n",
    "net.to(device)\n",
    "\n",
    "#Define optimizer, scheduler and the loss function\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d597ac-f886-454e-b245-593e72e0e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, train_loss = 0.0190, train_acc = 0.8882, test_loss = 0.0083, test_acc = 0.9552\n",
      "train speed = 4073.1702 images/s, test speed = 6908.0617 images/s\n",
      "epoch = 1, train_loss = 0.0066, train_acc = 0.9659, test_loss = 0.0054, test_acc = 0.9712\n",
      "train speed = 4541.4101 images/s, test speed = 10556.4562 images/s\n",
      "epoch = 2, train_loss = 0.0045, train_acc = 0.9778, test_loss = 0.0046, test_acc = 0.9744\n",
      "train speed = 4592.4925 images/s, test speed = 10618.9597 images/s\n",
      "epoch = 3, train_loss = 0.0034, train_acc = 0.9838, test_loss = 0.0042, test_acc = 0.9777\n",
      "train speed = 4585.2458 images/s, test speed = 10365.1217 images/s\n",
      "epoch = 4, train_loss = 0.0027, train_acc = 0.9882, test_loss = 0.0037, test_acc = 0.9814\n",
      "train speed = 4540.4732 images/s, test speed = 10695.3007 images/s\n",
      "epoch = 5, train_loss = 0.0022, train_acc = 0.9914, test_loss = 0.0033, test_acc = 0.9825\n",
      "train speed = 4541.5212 images/s, test speed = 10449.7839 images/s\n",
      "epoch = 6, train_loss = 0.0018, train_acc = 0.9932, test_loss = 0.0034, test_acc = 0.9819\n",
      "train speed = 4576.5668 images/s, test speed = 10471.6347 images/s\n",
      "epoch = 7, train_loss = 0.0015, train_acc = 0.9946, test_loss = 0.0032, test_acc = 0.9835\n",
      "train speed = 4536.6393 images/s, test speed = 10658.5016 images/s\n",
      "epoch = 8, train_loss = 0.0013, train_acc = 0.9957, test_loss = 0.0031, test_acc = 0.9849\n",
      "train speed = 4511.9295 images/s, test speed = 10589.7697 images/s\n",
      "epoch = 9, train_loss = 0.0011, train_acc = 0.9969, test_loss = 0.0029, test_acc = 0.9828\n",
      "train speed = 4537.2156 images/s, test speed = 10669.4103 images/s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_samples = 0\n",
    "    for img, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        label_onehot = torch.nn.functional.one_hot(label, 10).float()\n",
    "        out_fr = 0.\n",
    "        for t in range(num_steps):\n",
    "            encoded_img = encoder(img)\n",
    "            out_fr += net(encoded_img)\n",
    "        out_fr = out_fr/num_steps  \n",
    "        loss = loss_fun(out_fr, label_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_samples += label.numel()\n",
    "        train_loss += loss.item() * label.numel()\n",
    "        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "        #reset the membrane protential after each input image\n",
    "        functional.reset_net(net)\n",
    "\n",
    "    train_time = time.time()\n",
    "    train_speed = train_samples / (train_time - start_time)\n",
    "    train_loss /= train_samples\n",
    "    train_acc /= train_samples\n",
    "    \n",
    "    # lr_scheduler.step()\n",
    "        \n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    test_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in test_loader:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            label_onehot = torch.nn.functional.one_hot(label, 10).float()\n",
    "            out_fr = 0.   \n",
    "            for t in range(num_steps):\n",
    "                encoded_img = encoder(img)\n",
    "                out_fr += net(encoded_img)\n",
    "            out_fr = out_fr/num_steps  \n",
    "\n",
    "            loss = loss_fun(out_fr, label_onehot)\n",
    "\n",
    "            test_samples += label.numel()\n",
    "            test_loss += loss.item() * label.numel()\n",
    "            test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "            functional.reset_net(net)\n",
    "\n",
    "    test_time = time.time()\n",
    "    test_speed = test_samples / (test_time - train_time)\n",
    "    test_loss /= test_samples\n",
    "    test_acc /= test_samples\n",
    "\n",
    "    print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}')\n",
    "    print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd56c3d-ecf4-47e6-97e6-e6dd9986975e",
   "metadata": {},
   "source": [
    "### **Converting the trained SNN to HiAER Spike Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4153ff3-0b42-4101-b438-ff8602495150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized:  flat\n",
      "Quantized:  linear1\n",
      "Quantized:  lif1\n",
      "Quantized:  linear2\n",
      "Quantized:  lif2\n",
      "Quantization time: 0.0010223388671875\n",
      "Constructing axons from linear Layer\n",
      "Input layer shape(infeature, outfeature): [ 1 28 28] 1000\n",
      "Numer of neurons: 0, number of axons: 784\n",
      "Constructing neurons from linear Layer\n",
      "Hidden layer shape(infeature, outfeature):  (1000,) 10\n",
      "Numer of neurons: 1000, number of axons: 784\n"
     ]
    }
   ],
   "source": [
    "from hs_api.converter.cri_converter import CRI_Converter, Quantize_Network\n",
    "from hs_api.api import CRI_network\n",
    "import hs_bridge\n",
    "\n",
    "#Weight, Bias Quantization \n",
    "qn = Quantize_Network() \n",
    "net_quan = qn.quantize(net)\n",
    "\n",
    "#Set the parameters for conversion\n",
    "input_layer = 1 #first pytorch layer that acts as synapses\n",
    "output_layer = 4 #last pytorch layer that acts as synapses\n",
    "input_shape = (1, 28, 28)\n",
    "backend = 'spikingjelly'\n",
    "v_threshold = qn.v_threshold\n",
    "\n",
    "cn = CRI_Converter(num_steps = num_steps, \n",
    "                   input_layer = input_layer, \n",
    "                   output_layer = output_layer, \n",
    "                   input_shape = input_shape,\n",
    "                   backend=backend,\n",
    "                   v_threshold = v_threshold)\n",
    "cn.layer_converter(net_quan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d65ba4-c50c-4424-90fe-b1058e27c049",
   "metadata": {},
   "source": [
    "### **Initiate the HiAER Spike SNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5575e9-5974-4c0e-abf4-06bd5fb3315a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neuron' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_neuron_params\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_thr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(qn\u001b[38;5;241m.\u001b[39mv_threshold)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# #Have to be deployed on the FPGA\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# hardwareNetwork = CRI_network(dict(cn.axon_dict),\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#                               connections=dict(cn.neuron_dict),\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#                               config=config,target='CRI', \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#                               outputs = cn.output_neurons,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#                               coreID=1)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m softwareNetwork \u001b[38;5;241m=\u001b[39m \u001b[43mCRI_network\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxon_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mconnections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msimpleSim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_neurons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcoreID\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/HS/hs_api/hs_api/api.py:62\u001b[0m, in \u001b[0;36mCRI_network.__init__\u001b[0;34m(self, axons, connections, config, outputs, target, simDump, coreID)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimDump \u001b[38;5;241m=\u001b[39m simDump\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectome \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_connectome\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxons, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__format_input(copy\u001b[38;5;241m.\u001b[39mdeepcopy(axons),copy\u001b[38;5;241m.\u001b[39mdeepcopy(connections))\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRI\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/code/HS/hs_api/hs_api/api.py:86\u001b[0m, in \u001b[0;36mCRI_network.gen_connectome\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen_connectome\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mneuron\u001b[49m\u001b[38;5;241m.\u001b[39mreset_count() \u001b[38;5;66;03m#reset static variables for neuron class\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectome \u001b[38;5;241m=\u001b[39m connectome()\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m#add neurons/axons to connectome\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neuron' is not defined"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config['neuron_type'] = \"I&F\"\n",
    "config['global_neuron_params'] = {}\n",
    "config['global_neuron_params']['v_thr'] = int(qn.v_threshold)\n",
    "    \n",
    "# #Have to be deployed on the FPGA\n",
    "# hardwareNetwork = CRI_network(dict(cn.axon_dict),\n",
    "#                               connections=dict(cn.neuron_dict),\n",
    "#                               config=config,target='CRI', \n",
    "#                               outputs = cn.output_neurons,\n",
    "#                               coreID=1)\n",
    "\n",
    "softwareNetwork = CRI_network(dict(cn.axon_dict),\n",
    "                              connections=dict(cn.neuron_dict),\n",
    "                              config=config,target='simpleSim', \n",
    "                              outputs = cn.output_neurons,\n",
    "                              coreID=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3cfbd-df94-4546-8ca3-8689b8a25719",
   "metadata": {},
   "source": [
    "### **Deploying the SNN on HiAER Spike**\n",
    "\n",
    "run_sw and run_hw are two helper functions for running the spiking neural network on HiAER-Spike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc80f35-b960-49c2-9631-b7981cf23d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_sw(self,inputList,softwareNetwork):\n",
    "    predictions = []\n",
    "    total_time_cri = 0\n",
    "    #each image\n",
    "    for currInput in tqdm(inputList):\n",
    "        #reset the membrane potential to zero\n",
    "        softwareNetwork.simpleSim.initialize_sim_vars(len(self.neuron_dict))\n",
    "        spikeRate = [0]*10\n",
    "        #each time step\n",
    "        for slice in currInput:\n",
    "            start_time = time.time()\n",
    "            swSpike = softwareNetwork.step(slice, membranePotential=False)\n",
    "\n",
    "            end_time = time.time()\n",
    "            total_time_cri = total_time_cri + end_time-start_time\n",
    "            for spike in swSpike:\n",
    "                spikeIdx = int(spike) - self.bias_start_idx \n",
    "                try: \n",
    "                    if spikeIdx >= 0: \n",
    "                        spikeRate[spikeIdx] += 1 \n",
    "                except:\n",
    "                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate)\n",
    "        predictions.append(spikeRate.index(max(spikeRate)))\n",
    "    print(f\"Total simulation execution time: {total_time_cri:.5f} s\")\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669d786-cbab-4b5c-9b4c-ab2db0baeb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CRI_hw(self,inputList,hardwareNetwork):\n",
    "    predictions = []\n",
    "    #each image\n",
    "    total_time_cri = 0\n",
    "    for currInput in tqdm(inputList):\n",
    "        #initiate the hardware for each image\n",
    "        hs_bridge.FPGA_Execution.fpga_controller.clear(len(self.neuron_dict), False, 0)  ##Num_neurons, simDump, coreOverride\n",
    "        spikeRate = [0]*10\n",
    "        for slice in tqdm(currInput):\n",
    "            start_time = time.time()\n",
    "            hwSpike, latency, hbmAcc = hardwareNetwork.step(slice, membranePotential=False)\n",
    "            # print(f'hwSpike: {hwSpike}\\n. latency : {latency}\\n. hbmAcc:{hbmAcc}')\n",
    "            end_time = time.time()\n",
    "            total_time_cri = total_time_cri + end_time-start_time\n",
    "            for spike in hwSpike:\n",
    "                # print(int(spike))\n",
    "                spikeIdx = int(spike) - self.bias_start_idx \n",
    "                try: \n",
    "                    if spikeIdx >= 0: \n",
    "                        spikeRate[spikeIdx] += 1 \n",
    "                except:\n",
    "                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate)\n",
    "        predictions.append(spikeRate.index(max(spikeRate))) \n",
    "    print(f\"Total execution time CRIFPGA: {total_time_cri:.5f} s\")\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec6501-bb74-4f49-a7d0-dc8efc4baad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cri_convert.bias_start_idx = int(cri_convert.output_neurons[0])\n",
    "loss_fun = nn.MSELoss()\n",
    "start_time = time.time()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "test_samples = 0\n",
    "num_batches = 0\n",
    "\n",
    "RUN_HARDWARE = False #set to True if running on FPGA\n",
    "\n",
    "for img, label in tqdm(test_loader):\n",
    "    cri_input = cri_convert.input_converter(img)\n",
    "    output = None\n",
    "    if RUN_HARDWARE:\n",
    "        output = torch.tensor(run_CRI_hw(cri_input,hardwareNetwork), dtype=float)\n",
    "    else:\n",
    "        output = torch.tensor(run_CRI_sw(cri_input,softwareNetwork), dtype=float)\n",
    "    loss = loss_fun(output, label)\n",
    "    test_samples += label.numel()\n",
    "    test_loss += loss.item() * label.numel()\n",
    "    test_acc += (output == label).float().sum().item()\n",
    "    num_batches += 1\n",
    "test_time = time.time()\n",
    "test_speed = test_samples / (test_time - start_time)\n",
    "test_loss /= test_samples\n",
    "test_acc /= test_samples\n",
    "\n",
    "print(f'test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}')\n",
    "print(f'test speed ={test_speed: .4f} images/s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
